<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
<title>Ziniu Li</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publication.html">Publication</a></div>
<div class="menu-item"><a href="./docs/CV_Ziniu_Li.pdf">CV</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Ziniu Li</h1>
</div>
<table class="imgtable"><tr><td>
<img src="images/liziniu3.jpg" alt="alt text" width="210px" height="280px" />&nbsp;</td>
<td align="left"><p>Ph.D. student,<br />
<a href="https://sds.cuhk.edu.cn/en">School of Data Science</a>, <br />
<a href="https://www.cuhk.edu.cn/en">The Chinese University of Hong Kong, Shenzhen</a><br /></p>
<p>Email: ziniuli@link.cuhk.edu.cn</p>
<p><a href="https://twitter.com/ZiniuLi">[Twitter]</a> <a href="https://www.zhihu.com/people/mo-fei-10-41">[Zhihu]</a></p>
</td></tr></table>
<h2>About me</h2>
<p>I am a Ph.D. student at The Chinese University of Hong Kong, Shenzhen (CUHKSZ), advised by <a href="https://scholar.google.com/citations?user=dW3gcXoAAAAJ&amp;hl=en">Prof. Zhi-Quan (Tom) Luo</a>.</p>
<p>I am interested in artificial intelligence, especially reinforcement learning and large language models.</p>
<p>I have worked/interned at Tencent, Nanjing University, Cardinal Operations, etc.</p>
<p>Feel free to contact me if you want to discuss some ideas.</p>
<h2>Research Statement</h2>
<p>My research focuses on the algorithm design and theoretical analysis of machine learning models, particularly in reinforcement learning. Currently, I am primarily working on large language models to pursue the development of an agent capable of intelligent multi-task performance. My previous research outcomes are highlighted below:</p>
<p>In the field of large language models, my work spans several key areas: data selection (<a href="https://openreview.net/forum?id=vO04AzsB49">NeurIPS 2023, Spotlight</a>), diversity-preserving supervised fine-tuning (<a href="https://arxiv.org/abs/2408.16673">ICLR 2025</a>), computationally efficient RLHF (<a href="https://arxiv.org/abs/2310.10505">ICML 2024</a>), and hallucination mitigation (<a href="https://openreview.net/pdf?id=kX2EqGUp5B">ICLR 2025</a>).</p>
<p>In the field of imitation learning and reinforcement learning, I am interested in the theory of sample complexity (<a href="https://arxiv.org/abs/2010.11876">NeurIPS 2020</a>, <a href="https://ieeexplore.ieee.org/document/9485061">TPAMI 2021</a>, <a href="https://arxiv.org/abs/2306.06563">UAI 2023, Oral</a>), as well as applications in robotics (<a href="https://iclr-blog-track.github.io/2022/03/25/rethinking-valuedice">ICLR 2024 Blog</a>) and signal processing (<a href="https://ieeexplore.ieee.org/document/10634527">TSP 2024</a>).</p>
<p>I also work on optimization-centric topics with other researchers, including understanding Adam in training Transformers (<a href="https://arxiv.org/abs/2402.16788">NeurIPS 2024</a>), memory-efficient optimizers (<a href="https://arxiv.org/abs/2406.16793">ICLR 2025</a>), zero-order optimization (<a href="https://www.ijcai.org/proceedings/2020/205">IJCAI 2020</a>), and prompt-tuning (<a href="https://aclanthology.org/2024.findings-emnlp.871.pdf">EMNLP 2024</a>). </p>
<h2>Recent Highlights</h2>
<p>*: indicating equal contribution or alphabetic ordering.</p>
<div class="infoblock">
<div class="blockcontent">
<p><a href="https://arxiv.org/abs/2408.16673">Entropic Distribution Matching in Supervised Fine-tuning of LLMs: Less Overfitting and Better Diversity</a> <br />
<b>Ziniu Li</b>, Congliang Chen, Tian Xu, Zeyu Qin, Jiancong Xiao, Ruoyu Sun, Zhi-Quan Luo <br />
The 13th International Conference on Learning Representations (ICLR), 2025 <br /></p>
<p>TL;DR: <i>This work introduces a game-theoretic distribution matching method to address the diversity-reducing and knowledge-forgetting issues in SFT </i></p>
</div></div>
<div class="infoblock">
<div class="blockcontent">
<p><a href="https://arxiv.org/abs/2310.10505">ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for Aligning Large Language Models</a> <br />
<b>Ziniu Li</b>, Tian Xu, Yushun Zhang, Zhihang Lin, Yang Yu, Ruoyu Sun, Zhi-Quan Luo <br />
The 41st International Conference on Machine Learning (ICML), 2024  <br /></p>
<p>TL;DR: <i>This work shows that PPO overshoots for RLHF in LLMs and introduces ReMax, which requires half the memory of PPO and runs twice as fast </i></p>
</div></div>
<div class="infoblock">
<div class="blockcontent">
<p><a href="https://openreview.net/forum?id=lNEFatlsQb">When is RL better than DPO in RLHF? A Representation and Optimization Perspective</a> <br />
<b>Ziniu Li* </b>, Tian Xu*, Yang Yu <br />
<b>Oral</b> Presentation, The 12th International Conference on Learning Representations (ICLR) (Tiny Paper Track), 2024 <br /></p>
<p>TL;DR: <i>This work analyzes the reward modeling quality in view of representations and the optimization error sources </i></p>
</div></div>
<div class="infoblock">
<div class="blockcontent">
<p><a href="https://openreview.net/forum?id=vO04AzsB49">Imitation Learning from Imperfection: Theoretical Justifications and Algorithms</a> <br />
<b>Ziniu Li* </b>, Tian Xu*, Zeyu Qin, Yang Yu, Zhi-Quan Luo <br />
<b>Spotlight</b> Presentation (acceptance rate &lt; 5%), In Neural Information Processing System (NeurIPS) 37, 2023 <br /></p>
<p>TL;DR: <i>This work validates that importance sampling is effective in data selection when leveraging multiple imperfect (out-of-distribution and low-quality) data sources</i></p>
</div></div>
<h2>Service</h2>
<h4>Reviewer</h4>
<p>NeurIPS (<a href="https://neurips.cc/Conferences/2022/ProgramCommittee">Top Reviewer</a>), ICML (<a href="https://icml.cc/Conferences/2022/Reviewers">Outstanding Reviewer</a>), ICLR (<a href="https://iclr.cc/Conferences/2022/Reviewers">Highlighted Reviewer</a>).</p>
<h4>Teaching Assistant</h4>
<ul>
<li><p>DDA6111: Discrete Optimization. 2022 Spring @ CUHKSZ</p>
</li>
</ul>
<ul>
<li><p>DDA6060: Machine Learning. 2023 Spring @ CUHKSZ</p>
</li>
</ul>
<ul>
<li><p>FTE4560: Basic Machine Learning. 2021 Spring @ CUHKSZ.</p>
</li>
</ul>
<ul>
<li><p>CSC4120: Design and Analysis of Algorithms. 2022 Fall, 2021 Fall @ CUHKSZ</p>
</li>
</ul>
<ul>
<li><p>MAT3007: Introduction to Optimization. 2020 Fall @ CUHKSZ</p>
</li>
</ul>
<h4>Lecturer</h4>
<ul>
<li><p>Machine Learning (Summer Course for Senior High School Students) @ X ACADEMY 2022 TechX</p>
</li>
</ul>
<h2>Award</h2>
<ul>
<li><p>[2024-01] Runner-up of poster presentation award at the third doctoral and postdoctoral forum of Shenzhen Research Institute of Big Data. $5,000 CNY</p>
</li>
</ul>
<ul>
<li><p>[2023-12] Guo-Tai-Jun-An Scholarship. $20,000 CNY</p>
</li>
</ul>
<ul>
<li><p>[2021-04] Best oral presentation award at the first doctoral and postdoctoral forum of Shenzhen Research Institute of Big Data. $5,000 CNY</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
