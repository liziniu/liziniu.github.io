<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
<title></title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="publication.html" class="current">Publication</a></div>
<div class="menu-item"><a href="./docs/CV_Ziniu_Li.pdf">CV</a></div>
</td>
<td id="layout-content">
<h2>Publication</h2>
<p>*: indicating equal contribution or alphabetic ordering.</p>
<p><a href="https://scholar.google.com/citations?user=80UnKQQAAAAJ&amp;hl=en">Google Scholar</a>.</p>
<h3>Selective Publications</h3>
<table class="imgtable"><tr><td>
<img src="images/publication/2024_gem.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://arxiv.org/abs/2408.16673">Entropic Distribution Matching in Supervised Fine-tuning of LLMs: Less Overfitting and Better Diversity</a> </h4>
<p><b>Ziniu Li</b>, Congliang Chen, Tian Xu, Zeyu Qin, Jiancong Xiao, Ruoyu Sun, Zhi-Quan Luo <br /><br />
arXiv: 2408.16673 <br />
(<b>Oral</b> presentation at NeurIPS 2024 Workshop on Fine-Tuning in Modern Machine Learning: Principles and Scalability)</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2024_remax.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://arxiv.org/abs/2310.10505">ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for Aligning Large Language Models</a> </h4>
<p><b>Ziniu Li</b>, Tian Xu, Yushun Zhang, Zhihang Lin, Yang Yu, Ruoyu Sun, Zhi-Quan Luo <br /><br />
The 41st International Conference on Machine Learning (ICML), 2024 <br />
(The early version of this work is at arXiv:2310.10505)</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2023_selection.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://openreview.net/forum?id=vO04AzsB49">Imitation Learning from Imperfection: Theoretical Justifications and Algorithms</a> </h4>
<p><b>Ziniu Li* </b>, Tian Xu*, Zeyu Qin, Yang Yu, Zhi-Quan Luo <br /><br />
Conference onNeural Information Processing System (NeurIPS) 37, 2023 <br /> 
(<b>Spotlight</b> presentation, with an early version at arXiv:2301.11687)</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2022_hyperdqn.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://openreview.net/forum?id=X0nrKAXu7g-">HyperDQN: A Randomized Exploration Method for Deep Reinforcement Learning</a> <br /></h4>
<p><b>Ziniu Li</b>, Yingru Li, Yushun Zhang, Tong Zhang, Zhi-Quan Luo <br /><br />
The 10th International Conference on Learning Representations (ICLR), 2022 <br />
(<b>Oral</b> presentation at Workshop on Ecological Theory of Reinforcement Learning at NeurIPS, 2021)</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2021_error.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://ieeexplore.ieee.org/document/9485061">Error Bounds of Imitating Policies and Environments for Reinforcement Learning</a> <br /></h4>
<p>Tian Xu, <b>Ziniu Li</b>, Yang Yu <br /><br />
IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021</p>
</td></tr></table>
<h3>2024</h3>
<table class="imgtable"><tr><td>
<img src="images/publication/2024_hallucination.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://openreview.net/pdf?id=kX2EqGUp5B">Mitigating Hallucination in Large Vision-Language Models via Modular Attribution and Intervention</a> </h4>
<p>Tianyun Yang, <b>Ziniu Li</b>, Juan Cao, Chang Xu <br /><br />
NeurIPS Workshop on Adaptive Foundation Models, 2024 <br /></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2024_pruning.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://openreview.net/pdf?id=jD1eWpUMOf">Pruning for Robust Concept Erasing in Diffusion Models</a> </h4>
<p>Tianyun Yang, <b>Ziniu Li</b>, Juan Cao, Chang Xu <br /><br />
NeurIPS Workshop on Safe Generative AI, 2024 <br /></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2024_why_adam.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://arxiv.org/abs/2402.16788">Why Transformers Need Adam: A Hessian Perspective</a> </h4>
<p>Yushun Zhang, Congliang Chen, Tian Ding, <b>Ziniu Li</b>, Ruoyu Sun, Zhi-Quan Luo <br /><br />
Conference on Neural Information Processing System (NeurIPS) 38, 2024 <br /></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2024_zot.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://aclanthology.org/2024.findings-emnlp.871.pdf">Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization</a> </h4>
<p>Heshen Zhan, Congliang Chen, Tian Ding, <b>Ziniu Li</b>, Ruoyu Sun <br /><br />
The 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP) (Findings), 2024 <br /></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2024_gem.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://arxiv.org/abs/2408.16673">Entropic Distribution Matching in Supervised Fine-tuning of LLMs: Less Overfitting and Better Diversity</a> </h4>
<p><b>Ziniu Li</b>, Congliang Chen, Tian Xu, Zeyu Qin, Jiancong Xiao, Ruoyu Sun, Zhi-Quan Luo <br /><br />
arXiv: 2408.16673 <br />
(<b>Oral</b> presentation at NeurIPS 2024 Workshop on Fine-Tuning in Modern Machine Learning: Principles and Scalability)</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2024_radar.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://ieeexplore.ieee.org/document/10634527">Sensing Jamming Strategy from Limited Observations: An Imitation Learning Perspective</a> </h4>
<p>Youlin Fan, Bo Jiu, Wenqiang Pu, <b>Ziniu Li</b>, Kang Li, Hongwei Liu <br /><br />
IEEE Transactions on Signal Processing (TSP)</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2024_adam_mini.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://arxiv.org/abs/2406.16793">Adam-mini: Use Fewer Learning Rates To Gain More</a> </h4>
<p>Yushun Zhang, Congliang Chen, <b>Ziniu Li</b>, Tian Ding, Chenwei Wu, Yinyu Ye, Zhi-Quan Luo, Ruoyu Sun <br /><br />
arXiv:2406.16793 <br /></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2024_bwarea.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://arxiv.org/abs/2405.17039">BWArea Model: Learning World Model, Inverse Dynamics, and Policy for Controllable Language Generation</a> </h4>
<p>Chengxing Jia, Pengyuan Wang, <b>Ziniu Li</b>, Yi-Chen Li, Zhilong Zhang, Nan Tang, Yang Yu <br /><br />
arXiv:2405.17039 <br /> </p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2024_preference.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://arxiv.org/abs/2405.16455">On the Algorithmic Bias of Aligning Large Language Models with RLHF: Preference Collapse and Matching Regularization</a> </h4>
<p>Jiancong Xiao, <b>Ziniu Li</b>, Xingyu Xie, Emily Getzen, Cong Fang, Qi Long, Weijie J. Su <br /><br />
arXiv:2405.16455 <br /></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2024_remax.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://arxiv.org/abs/2310.10505">ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for Aligning Large Language Models</a> </h4>
<p><b>Ziniu Li</b>, Tian Xu, Yushun Zhang, Zhihang Lin, Yang Yu, Ruoyu Sun, Zhi-Quan Luo <br /><br />
The 41st International Conference on Machine Learning (ICML), 2024 <br />
(The early version of this work is at arXiv:2310.10505)</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2024_dpo.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://openreview.net/forum?id=lNEFatlsQb">When is RL better than DPO in RLHF? A Representation and Optimization Perspective</a> </h4>
<p><b>Ziniu Li*</b>, Tian Xu*, Yang Yu <br /><br />
The 12th International Conference on Learning Representations (ICLR) (Tiny Paper Track), 2024 <br />
(<b>Oral</b> presentation, with an early version at arXiv:2312.10584)</p>
</td></tr></table>
<h3>2023</h3>
<table class="imgtable"><tr><td>
<img src="images/publication/2023_selection.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://openreview.net/forum?id=vO04AzsB49">Imitation Learning from Imperfection: Theoretical Justifications and Algorithms</a> </h4>
<p><b>Ziniu Li* </b>, Tian Xu*, Zeyu Qin, Yang Yu, Zhi-Quan Luo <br /><br />
Conference onNeural Information Processing System (NeurIPS) 37, 2023 <br /> 
(<b>Spotlight</b> presentation, with an early version at arXiv:2301.11687)</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2023_ail.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://arxiv.org/abs/2306.06563">Provably Efficient Adversarial Imitation Learning with Unknown Transitions</a> </h4>
<p>Tian Xu*, <b>Ziniu Li* </b>, Yang Yu, Zhi-Quan Luo <br /><br />
The 39th Conference on Uncertainty in Artificial Intelligence (UAI), 2023 <br />
(<b>Oral</b> presentation, with an early version at arXiv:2106.10424v2)</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2023_expert.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://arxiv.org/abs/2303.07046">Deploying Offline Reinforcement Learning with Human Feedback</a> </h4>
<p><b>Ziniu Li</b>, Ke Xu, Liu Liu, Lanqing Li, Deheng Ye, Peilin Zhao <br /><br />
arXiv:2303.07046 <br /></p>
</td></tr></table>
<h3>2022</h3>
<table class="imgtable"><tr><td>
<img src="images/publication/2022_understanding.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://arxiv.org/abs/2208.01899">Understanding Adversarial Imitation Learning in Small Sample Regime: A Stage-coupled Analysis</a> </h4>
<p>Tian Xu*, <b>Ziniu Li* </b>, Yang Yu, Zhi-Quan Luo <br /><br />
arXiv:2208.01899 <br />
(The early version of this work is at arXiv:2106.10424v3)</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2022_valuedice.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://iclr-blog-track.github.io/2022/03/25/rethinking-valuedice/">Rethinking ValueDice: Does It Really Improve Performance?</a> <br /></h4>
<p><b>Ziniu Li* </b>, Tian Xu*, Yang Yu, Zhi-Quan Luo <br /><br />
The 10th International Conference on Learning Representations (ICLR) (Blog Track), 2022 <br /></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2022_qlearning.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://arxiv.org/abs/2203.11489">A Note on Target Q-learning for Solving Finite MDPs with A Generative Oracle</a> <br /></h4>
<p><b>Ziniu Li*</b>, Tian Xu*, Yang Yu <br /><br />
arXiv:2203.11489</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2022_hyperdqn.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://openreview.net/forum?id=X0nrKAXu7g-">HyperDQN: A Randomized Exploration Method for Deep Reinforcement Learning</a> <br /></h4>
<p><b>Ziniu Li</b>, Yingru Li, Yushun Zhang, Tong Zhang, Zhi-Quan Luo <br /><br />
The 10th International Conference on Learning Representations (ICLR), 2022 <br />
(<b>Oral</b> presentation at Workshop on Ecological Theory of Reinforcement Learning at NeurIPS, 2021)</p>
</td></tr></table>
<h3>2021</h3>
<table class="imgtable"><tr><td>
<img src="images/publication/2021_imitation.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="http://www.lamda.nju.edu.cn/xut/Imitation_Learning.pdf">A Concise Introduction to Imitation Learning</a> (In Chinese) <br /></h4>
<p>Tian Xu, <b>Ziniu Li</b>, Yang Yu <br /><br />
Online Available</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2021_error.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://ieeexplore.ieee.org/document/9485061">Error Bounds of Imitating Policies and Environments for Reinforcement Learning</a> <br /></h4>
<p>Tian Xu, <b>Ziniu Li</b>, Yang Yu <br /><br />
IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021</p>
</td></tr></table>
<h3>2020</h3>
<table class="imgtable"><tr><td>
<img src="images/publication/2020_error.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://arxiv.org/abs/2010.11876">Error Bounds of Imitating Policies and Environments</a> <br /></h4>
<p>Tian Xu, <b>Ziniu Li</b>, Yang Yu <br /><br />
Conference on Neural Information Processing Systems 34 (NeurIPS), 2020.</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2020_novelty.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="docs/dai2020_paper.pdf">Efficient Exploration by Novelty-pursuit</a> <br /></h4>
<p><b>Ziniu Li*</b>, Xiong-Hui Chen* <br /><br />
The 2nd International Conference on Distributed Artificial Intelligence (DAI), 2020</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/publication/2020_sges.png" alt="alt text" width="180px" height="120px" />&nbsp;</td>
<td align="left"><h4><a href="https://www.ijcai.org/proceedings/2020/205">Self-Guided Evolution Strategies with Historical Estimated Gradients</a> <br /></h4>
<p>Fei-yu Liu, <b>Ziniu Li</b>, Chao Qian <br /><br />
The 29th International Conference on Joint Artificial Intelligence (IJCAI), 2020</p>
</td></tr></table>
</td>
</tr>
</table>
</body>
</html>
