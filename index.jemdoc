# jemdoc: menu{MENU}{index.html}, nofooter
==Ziniu Li

~~~
{}{img_left}{images/liziniu3.jpg}{alt text}{210}{280}{}
Ph.D. student,\n
[https://sds.cuhk.edu.cn/en School of Data Science], \n
[https://www.cuhk.edu.cn/en The Chinese University of Hong Kong, Shenzhen]\n

Email: ziniuli@link.cuhk.edu.cn

[https://twitter.com/ZiniuLi \[Twitter\] ] [https://www.zhihu.com/people/mo-fei-10-41 \[Zhihu\] ]
~~~

== About me

I am a Ph.D. student at The Chinese University of Hong Kong, Shenzhen (CUHKSZ), advised by [https://scholar.google.com/citations?user=dW3gcXoAAAAJ&hl=en Prof. Zhi-Quan (Tom) Luo].

My research interests include reinforcement learning theory, algorithms, and applications.

I have worked/interned at Tencent, Nanjing University, Cardinal Operations, etc.

My curriculum vitae can be downloaded from [docs/CV_Ziniu_Li.pdf here].

Feel free to contact me if you want to discuss some ideas.

== Selected Work

*: indicating equal contribution or alphabetic ordering.

- [https://arxiv.org/abs/2301.11687 Theoretical Analysis of Offline Imitation With Supplementary Dataset] \n
  *Ziniu Li\* *, Tian Xu\*, Yang Yu, Zhi-Quan Luo \n
  arXiv:2301.11687 \n
  (This work explores an emerging framework of supplementing expert data using an additional sub-optimal dataset, \n providing a data-centric solution to offline imitation learning)


- [https://arxiv.org/abs/2208.01899 Understanding Adversarial Imitation Learning in Small Sample Regime: A Stage-coupled Analysis] \n
  Tian Xu\*, *Ziniu Li\* *, Yang Yu, Zhi-Quan Luo \n
  arXiv:2208.01899 \n
  (This work presents the first horizon-free sample complexity bound of adversarial imitation learning (AIL), \n providing an answer to the open question --why does AIL outperform BC by a wide margin, particularly in the low data regime ? --\n raised in CoRL 2019 best paper by Ghasemipour et al.)


- [https://iclr-blog-track.github.io/2022/03/25/rethinking-valuedice/ Rethinking ValueDice: Does It Really Improve Performance?] \n
  *Ziniu Li\* *, Tian Xu\*, Yang Yu, Zhi-Quan Luo \n
  In Proceedings of the 10th International Conference on Learning Representations (ICLR) (Blog Track), 2022 \n
  (This work presents the first reduction of offline AIL to BC through a new DP-based analysis, \n proving that AIL is no better than BC in the offline setting and verifying this by experiments)


== Service

==== Reviewer

NeurIPS ([https://neurips.cc/Conferences/2022/ProgramCommittee Top Reviewer]), ICML ([https://icml.cc/Conferences/2022/Reviewers Outstanding Reviewer]), ICLR ([https://iclr.cc/Conferences/2022/Reviewers Highlighted Reviewer]).

==== Teaching Assistant

- DDA6111: Discrete Optimization. 2022 Spring @ CUHKSZ

- DDA6060: Machine Learning. 2023 Spring @ CUHKSZ

- FTE4560: Basic Machine Learning. 2021 Spring @ CUHKSZ.

- CSC4120: Design and Analysis of Algorithms. 2022 Fall, 2021 Fall @ CUHKSZ

- MAT3007: Introduction to Optimization. 2020 Fall @ CUHKSZ

==== Lecturer

- Machine Learning (Summer Course for Senior High School Students) @ X ACADEMY 2022 TechX

== Award

- \[2021-04\] Best oral presentation award at the first doctoral and postdoctoral forum of Shenzhen Research Institute of Big Data.
